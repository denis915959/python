# python lab4.txt




import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from multiprocessing import freeze_support
import matplotlib.pyplot as plt

if __name__ == '__main__':
    freeze_support()
    transform = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.5,), (0.5,))])

    test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())
    train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())
    test_loader = DataLoader(test_set, batch_size=8, shuffle=True, num_workers=2) #5 не получилось
    train_loader = DataLoader(train_set, batch_size=8, shuffle=True, num_workers=2) 

    classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')  # определяет имена классов

    # Define the CNN Model
    class Net(torch.nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.conv1 = torch.nn.Conv2d(
                in_channels=1, out_channels=6, kernel_size=5)
            self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)
            self.conv2 = torch.nn.Conv2d(
                in_channels=6, out_channels=12, kernel_size=5)
            self.fc1 = torch.nn.Linear(in_features=12*4*4, out_features=120)
            self.fc2 = torch.nn.Linear(in_features=120, out_features=60)
            self.fc3 = torch.nn.Linear(in_features=60, out_features=10)

        def forward(self, x):
            x = self.pool(torch.nn.functional.relu(self.conv1(x)))
            x = self.pool(torch.nn.functional.relu(self.conv2(x)))
            x = x.view(-1, 12*4*4)
            x = torch.nn.functional.relu(self.fc1(x))
            x = torch.nn.functional.relu(self.fc2(x))
            x = self.fc3(x)
            return x

    autoencoder = Net()

    criteria = torch.nn.CrossEntropyLoss()  #у Дениса другой критерий
    optimizer = torch.optim.SGD(autoencoder.parameters(), lr=0.001, momentum=0.9)

    # Train the network
    for epoch in range(10):
        running_loss = 0.0
        for i, data in enumerate(train_loader, 0):
            inputs, labels = data
            optimizer.zero_grad()
            outputs = autoencoder(inputs)
            loss = criteria(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            if (i % 10000 == 6999): #1000 == 999:  # выводим каждую тысячу образцов
                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 1000))
                running_loss = 0.0

    print('Finished Training')

    # Выводим тестовые примеры и соответствующие выходы модели.
    with torch.no_grad():
        for data in test_loader:
            img, _ = data
            img = img.to(torch.device('cpu'))
            output = autoencoder(img) #img заменить
            #loss = criterion(output, img)
            fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))
            for images, row in zip([img, output], axes):
                for img, ax in zip(images, row):
                    ax.imshow(img[0], cmap='gray')
                    ax.get_xaxis().set_visible(False)
                    ax.get_yaxis().set_visible(False)
            fig.suptitle('Original Images and Reconstructed Images')
            plt.show()
            #print('Test Loss: {:.4f}'.format(loss.item()))
            break













"""
    with torch.no_grad():
        dataiter = iter(test_loader)
        images, labels = dataiter.__next__()
        outputs = autoencoder(images)
        _, predicted = torch.max(outputs, 1)

        # Отображаем примеры входных изображений и соответствующих выходов модели.
        fig, ax = plt.subplots(nrows=2, ncols=4)
        for j, ax in enumerate(ax.flatten()):
            plt.imshow(images[j][0], cmap='gray')  #вот это вернуть?? с plt
            ax.set_title(f'Predicted: {classes[predicted[j]]}')
        plt.show()

        # Clear previous figures
        #plt.clf()  #не работает

        fig, ax = plt.subplots(nrows=2, ncols=4)
        for j, ax in enumerate(ax.flatten()):
            plt.imshow(images[j][0], cmap='gray')
            ax.set_title(f'Predicted: {classes[predicted[j]]}')
        plt.show()

        total_loss = 0
        total = 0

        for data in test_loader:
            images, labels = data

            output = autoencoder(images)
            loss = criteria(output, labels)
            total_loss += loss.item()
            total += labels.size(0)

        print(f'Test Loss: {total_loss / total:.3f}')
"""















"""import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from multiprocessing import freeze_support

if __name__ == '__main__':
    freeze_support()
    transform = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.5,), (0.5,))])

    testset = torchvision.datasets.MNIST(root='./data', train=False,
                                         download=True, transform=transform)
    testloader = DataLoader(testset, batch_size=4,
                             shuffle=True, num_workers=2)

    classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')  #определяет имена классов

    # Define the CNN Model
    class Net(torch.nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.conv1 = torch.nn.Conv2d(
                in_channels=1, out_channels=6, kernel_size=5)
            self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)
            self.conv2 = torch.nn.Conv2d(
                in_channels=6, out_channels=12, kernel_size=5)
            self.fc1 = torch.nn.Linear(in_features=12*4*4, out_features=120)
            self.fc2 = torch.nn.Linear(in_features=120, out_features=60)
            self.fc3 = torch.nn.Linear(in_features=60, out_features=10)

        def forward(self, x):
            x = self.pool(torch.nn.functional.relu(self.conv1(x)))
            x = self.pool(torch.nn.functional.relu(self.conv2(x)))
            x = x.view(-1, 12*4*4)
            x = torch.nn.functional.relu(self.fc1(x))
            x = torch.nn.functional.relu(self.fc2(x))
            x = self.fc3(x)
            return x

    net = Net()

    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

    # Train the network
    for epoch in range(10):
        running_loss = 0.0
        for i, data in enumerate(testloader, 0):
            inputs, labels = data
            optimizer.zero_grad()
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            if i % 10 == 100: #9    
                print('[%d, %5d] loss: %.4f' %
                      (epoch + 1, i + 1, running_loss / 10))
                running_loss = 0.0

"""


"""with torch.no_grad():
    for data in test_loader:
        img, _ = data
        img = img.to(torch.device('cpu'))
        output = model(img)
        loss = criterion(output, img)
        fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))
        for images, row in zip([img, output], axes):
            for img, ax in zip(images, row):
                ax.imshow(img[0], cmap='gray')
                ax.get_xaxis().set_visible(False)
                ax.get_yaxis().set_visible(False)
        fig.suptitle('Original Images and Reconstructed Images')
        plt.show()
        print('Test Loss: {:.4f}'.format(loss.item()))
        break"""



"""print("Encoder:")
print(net.encoder)
print("Decoder:")
print(net.decoder)"""