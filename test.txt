# python test.txt

"""from scipy.optimize import linear_sum_assignment
import numpy as np

A = np.random.rand(5, 5) # пример квадратной матрицы размера 5х5

print(A)

row_ind, col_ind = linear_sum_assignment(A) # вызов венгерского алгоритма
print(row_ind)
print(col_ind)
print(A[row_ind, col_ind]) # вывод оптимального соответствия столбцов и строк матрицы A"""



import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

# загрузка датасета MNIST
trainset = torchvision.datasets.MNIST(root='./data', train=True,
                                      download=True, transform=torchvision.transforms.ToTensor())
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)

# определение класса автокодировщика
class Autoencoder(nn.Module):
    def __init__(self, encoding_dim):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(28*28, 256),
            nn.ReLU(True),
            nn.Linear(256, encoding_dim),
            nn.ReLU(True))
        self.decoder = nn.Sequential(
            nn.Linear(encoding_dim, 256),
            nn.ReLU(True),
            nn.Linear(256, 28*28),
            nn.Sigmoid())

    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# создание экземпляра автокодировщика
autoencoder = Autoencoder(encoding_dim=64)

# определение функции потерь и оптимизатора
criterion = nn.BCELoss()
optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)

# обучение автокодировщика
for epoch in range(10):  # 10 эпох
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        inputs, _ = data
        optimizer.zero_grad()
        outputs = autoencoder(inputs)
        loss = criterion(outputs, inputs.view(-1, 28*28))
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    print('[%d] loss: %.3f' % (epoch + 1, running_loss / len(trainloader)))

# отображение результата работы автокодировщика на тестовых данных
testset = torchvision.datasets.MNIST(root='./data', train=False,
                                     download=True, transform=torchvision.transforms.ToTensor())
testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                         shuffle=False, num_workers=2)
dataiter = iter(testloader)
images, labels = dataiter.__next__()
output = autoencoder(images)
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(images[i].squeeze(), cmap='gray')
    plt.subplot(2, 4, i+5)
    plt.imshow(output[i].detach().numpy().reshape(28, 28), cmap='gray')
plt.show()